{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Title: top level file for ASL net\n",
    "#\n",
    "# Author: Mansur Amin\n",
    "#\n",
    "# Description: Top leve file for ASL NN.\n",
    "#\n",
    "# Current Status: Calls all functions and imports all files needed to run\n",
    "# training net.\n",
    "################################################################################\n",
    "\n",
    "# libraries\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ASL_Class as asl\n",
    "import torch\n",
    "import torch.autograd as ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Normalize_MNIST_images', (27456, 784))\n",
      "('Normalize_MNIST_images', (7173, 784))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#####################################################################\n",
    "# Main Program\n",
    "#####################################################################\n",
    "\n",
    "####### Read data\n",
    "\n",
    "# Windows Path\n",
    "# train_path = 'C:\\\\Users\\\\maamin\\\\Desktop\\\\ECE_285_ML_DL\\\\data\\\\sign_mnist_train.csv'\n",
    "# test_path = 'C:\\\\Users\\\\maamin\\\\Desktop\\\\ECE_285_ML_DL\\\\data\\\\sign_mnist_test.csv'\n",
    "\n",
    "# Mac path\n",
    "# train_path = '/Users/mansuramin/Desktop/ECE_285_ML/data/sign_mnist_train.csv'\n",
    "# test_path = '/Users/mansuramin/Desktop/ECE_285_ML/data/sign_mnist_test.csv'\n",
    "\n",
    "# Linux Server Path\n",
    "train_path = '/datasets/home/56/256/maamin/asl_data/sign_mnist_train.csv'\n",
    "test_path = '/datasets/home/56/256/maamin/asl_data/sign_mnist_test.csv'\n",
    "\n",
    "# Load data\n",
    "xtrain,ltrain = asl.read_data(train_path)\n",
    "xtest,ltest = asl.read_data(test_path)\n",
    "\n",
    "# Normalize\n",
    "xtrain = asl.normalize_MNIST_images(xtrain)\n",
    "xtest = asl.normalize_MNIST_images(xtest)\n",
    "\n",
    "# Visualize data\n",
    "indx = 10240\n",
    "asl.vis_data(xtrain[indx,:],ltrain[indx])\n",
    "\n",
    "# Change Types and reshape\n",
    "xtrain = np.moveaxis(xtrain,0,1)\n",
    "ltrain = ltrain.astype(np.int64)\n",
    "xtest = np.moveaxis(xtest,0,1)\n",
    "ltest = ltest.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain2 =  (28, 28, 1, 27456)\n",
      "xtrain =  (27456, 1, 28, 28)\n",
      "xtest2 =  (28, 28, 1, 7173)\n",
      "xtest =  (7173, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Reshape data in the form of \n",
    "# Batch size × Number of input channels × Image width × Image height\n",
    "xtrain2 = xtrain.reshape(28,28,1,xtrain.shape[1])\n",
    "xtest2 = xtest.reshape(28,28,1,xtest.shape[1])\n",
    "xtrain = np.moveaxis(xtrain2,[2,3],[1,0])\n",
    "xtest = np.moveaxis(xtest2,[2,3],[1,0])\n",
    "\n",
    "# Print new vectors eo make sure deminsions are correct\n",
    "print(\"xtrain2 = \", xtrain2.shape)\n",
    "print(\"xtrain = \", xtrain.shape)\n",
    "print(\"xtest2 = \", xtest2.shape)\n",
    "print(\"xtest = \", xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from numpy to torch tensor\n",
    "xtrain = torch.from_numpy(xtrain)\n",
    "ltrain = torch.from_numpy(ltrain)\n",
    "xtest = torch.from_numpy(xtest)\n",
    "\n",
    "# place data on GPU's \n",
    "if torch.cuda.is_available() :\n",
    "    xtrain = xtrain.cuda()\n",
    "    ltrain = ltrain.cuda()\n",
    "    xtest  = xtest.cuda()\n",
    "\n",
    "# wrap tensor in autograd variable that lets you keep track of gradient for backprop\n",
    "xtrain = ag.Variable(xtrain,requires_grad = True)\n",
    "ltrain = ag.Variable(ltrain,requires_grad = False)\n",
    "xtest  = ag.Variable(xtest ,requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## Initalizing LeNet network\n",
    "\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "# this is our neural netowkrs class that inherits from nn.Module\n",
    "class LeNet(nn.Module) : \n",
    "    # here we defin our network structure\n",
    "    def __init__(self) :\n",
    "        super(LeNet,self).__init__()\n",
    "        if torch.cuda.is_available() :\n",
    "            self.conv1 = nn.Conv2d(1,6,5).double().cuda()  # output 24x24 \n",
    "            self.conv2 = nn.Conv2d(6,16,5).double().cuda()\n",
    "            self.fc1   = nn.Linear(256,120).double().cuda()\n",
    "            self.fc2   = nn.Linear(120,84).double().cuda()\n",
    "            self.fc3   = nn.Linear(84,10).double().cuda()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
    "        x = x.view(-1,self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    def num_flat_features(self, x) :\n",
    "        size = x.size()[1:]\n",
    "        return np.prod(size)\n",
    "\n",
    "net = LeNet()\n",
    "print(net)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([6, 1, 5, 5])\n",
      "1 torch.Size([6])\n",
      "2 torch.Size([16, 6, 5, 5])\n",
      "3 torch.Size([16])\n",
      "4 torch.Size([120, 256])\n",
      "5 torch.Size([120])\n",
      "6 torch.Size([84, 120])\n",
      "7 torch.Size([84])\n",
      "8 torch.Size([10, 84])\n",
      "9 torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "for i in range(len(params)) : \n",
    "    print(i, params[i].size())\n",
    "    # 0 = output of conv1\n",
    "    # 2 = output of conv2\n",
    "    # 4,6,8 = fully connected layers\n",
    "    # 1,3,5,7,9 = output of maxpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available() :\n",
    "    yinit = net(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.064408197406943\n"
     ]
    }
   ],
   "source": [
    "# print(100 * np.mean(ltest == yinit.data.numpy().T.argmax(axis =0)))\n",
    "\n",
    "print(100 * np.mean(ltest == yinit.cpu().data.numpy().T.argmax(axis =0)))\n",
    "# probability of success for 10 digits after feed forward path ith no back propigation\n",
    "# if you have two classes probability of success is 50 % or 1/2\n",
    "# if you have ten classes probability of success is 10% or 1/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minibatch gradient descent ith cross entropy \n",
    "N = xtrain.size()[0]            # training set size \n",
    "B = 100                         # minibatch size\n",
    "NB = N / B                      # number of minibatches\n",
    "T = 10                          # number of epochs\n",
    "gamma = .001                    # learning rate\n",
    "rho = .9                        # momentup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr=gamma,momentum=rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1523240155148/work/torch/lib/THCUNN/SoftMaxCommon.cuh:464",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-cfebbde2af44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# back propigation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# paramater update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1523240155148/work/torch/lib/THCUNN/SoftMaxCommon.cuh:464"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(T) :\n",
    "    running_loss = 0.0\n",
    "    idxminibathches = np.random.permutation(NB) # shuffling \n",
    "    \n",
    "    for k in range (NB) :\n",
    "        i = idxminibathches[k] # index of minibatch\n",
    "        \n",
    "        # extract i-th minibatch from xtrain and ltrain \n",
    "        idxsmp = np.arange(i*B,np.min((i*B+B,N)))          # indicies of samples for i-th minibatch\n",
    "        \n",
    "        inputs = xtrain[idxsmp]\n",
    "        labels = ltrain[idxsmp]\n",
    "        \n",
    "        # initalize the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward propigation \n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # error evulation \n",
    "        loss = criterion(outputs,labels)\n",
    "\n",
    "        # back propigation \n",
    "        loss.backward()\n",
    "\n",
    "        # paramater update\n",
    "        optimizer.step()\n",
    "        \n",
    "        B = 10\n",
    "        # print averaged loss per minibatch every 100 minibatches\n",
    "        running_loss += loss[0]\n",
    "        if k %B  == B-1 :\n",
    "            print('[%d, %5d] loss: %3f' % (epoch+1, k+1, running_loss/B))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        B = 100\n",
    "print ('Finished Training')\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing phase\n",
    "if torch.cuda.is_available() :\n",
    "    yinit = net(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(100 * np.mean(ltest == yinit.cpu().data.numpy().T.argmax(axis =0)))\n",
    "# probability of success for 10 digits after feed forward path ith no back propigation\n",
    "# if you have two classes probability of success is 50 % or 1/2\n",
    "# if you have ten classes probability of success is 10% or 1/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words with the most # of examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Full Path</th>\n",
       "      <th># samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ART-DESIGN</td>\n",
       "      <td>data_cleaned\\ART-DESIGN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>CUTE</td>\n",
       "      <td>data_cleaned\\CUTE</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ADVISE-INFLUENCE</td>\n",
       "      <td>data_cleaned\\ADVISE-INFLUENCE</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>PAST</td>\n",
       "      <td>data_cleaned\\PAST</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>GUITAR</td>\n",
       "      <td>data_cleaned\\GUITAR</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>GOVERNMENT</td>\n",
       "      <td>data_cleaned\\GOVERNMENT</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AFRAID</td>\n",
       "      <td>data_cleaned\\AFRAID</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>BIG</td>\n",
       "      <td>data_cleaned\\BIG</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ANSWER</td>\n",
       "      <td>data_cleaned\\ANSWER</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AGAIN</td>\n",
       "      <td>data_cleaned\\AGAIN</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Word                      Full Path  # samples\n",
       "46         ART-DESIGN        data_cleaned\\ART-DESIGN         32\n",
       "185              CUTE              data_cleaned\\CUTE         30\n",
       "15   ADVISE-INFLUENCE  data_cleaned\\ADVISE-INFLUENCE         24\n",
       "261              PAST              data_cleaned\\PAST         24\n",
       "207            GUITAR            data_cleaned\\GUITAR         24\n",
       "205        GOVERNMENT        data_cleaned\\GOVERNMENT         24\n",
       "16             AFRAID            data_cleaned\\AFRAID         24\n",
       "95                BIG               data_cleaned\\BIG         24\n",
       "37             ANSWER            data_cleaned\\ANSWER         22\n",
       "18              AGAIN             data_cleaned\\AGAIN         22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "from IPython.core.display import display\n",
    "\n",
    "# first lets look at the data\n",
    "dataFolder = 'data_cleaned'\n",
    "wordLists = os.listdir(dataFolder)\n",
    "\n",
    "#populate the data frame with words\n",
    "ASL_df = pd.DataFrame(wordLists,columns = ['Word']);\n",
    "#populate with full paths\n",
    "ASL_df['Full Path'] = ASL_df['Word'].apply(lambda x: os.path.join(dataFolder,x))\n",
    "#populate with # samples\n",
    "ASL_df['# samples'] = ASL_df['Full Path'].apply(lambda x: len(os.listdir(x)))\n",
    "\n",
    "#sort them by largest or smallest\n",
    "ASL_df = ASL_df.sort_values(by=['# samples'],ascending = False)\n",
    "\n",
    "print('Words with the most # of examples')\n",
    "display(ASL_df.head(10))\n",
    "print(ASL_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, None, None, 512)   14714688  \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "import cv2\n",
    "\n",
    "def getImagesFromVideoFile(videoName):\n",
    "    #get video source object\n",
    "    cap = cv2.VideoCapture(videoName)\n",
    "    w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    numFrames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    size = (h,w)\n",
    "    vid_Frames = [] #initialize\n",
    "    \n",
    "    if(cap.isOpened()):\n",
    "        while(True):\n",
    "            #read the captured video\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if(not ret):\n",
    "                #no more frames so lets exit the loop\n",
    "                break\n",
    "            im = cv2.resize(frame, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "            #now lets just cast it and fix the channels\n",
    "            im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB).astype(np.float64)\n",
    "            vid_Frames.append(im)\n",
    "    else:\n",
    "        print('Something wrong with VideoCapture')\n",
    "    #release the object\n",
    "    cap.release()\n",
    "    return vid_Frames,size,numFrames\n",
    "\n",
    "        \n",
    "#lets load the model\n",
    "FeatureExtractor = Sequential()\n",
    "conv_base = VGG16(weights='imagenet', include_top=False)\n",
    "FeatureExtractor.add(conv_base)\n",
    "# FeatureExtractor.add(GlobalAveragePooling2D()) # to reduce dimension for the the RNN\n",
    "\n",
    "            \n",
    "FeatureExtractor.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breaking out\n",
      "Processing 176.0 frames\n",
      "Starting Feature Extraction\n",
      "Total Time: 2.985128446420034 mins \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "NumClasses = 1\n",
    "for index, row in ASL_df.head(NumClasses).iterrows():\n",
    "    #get the full paths of the videos\n",
    "    videoNameSources = [os.path.join(row['Full Path'],x) for x in os.listdir(row['Full Path'])]\n",
    "    for i, videoName in enumerate(videoNameSources):\n",
    "        vid_Frames,size,numFrames = getImagesFromVideoFile(videoName)\n",
    "        #lets create the destination directory\n",
    "        baseDirectory = 'data_features'\n",
    "        if not os.path.exists(baseDirectory):\n",
    "            os.makedirs(baseDirectory)\n",
    "        destDirectory = os.path.join(baseDirectory,row['Word'] + '_'+str(i))\n",
    "        #now lets extract the features in batch\n",
    "        print('Processing {} frames'.format(numFrames))\n",
    "        print('Starting Feature Extraction')\n",
    "        start = time.time()\n",
    "        x = np.array(vid_Frames) # create the mult-dim array\n",
    "        x = preprocess_input(x) # process input to work with the VGG network\n",
    "        y = FeatureExtractor.predict(x) # extract Features\n",
    "        \n",
    "        end = time.time()\n",
    "        print('Total Time: {} mins \\n'.format((end-start)/60))\n",
    "        \n",
    "        # now lets save the features to the destination directory \n",
    "        np.save(destDirectory, y)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words with the most # of examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Full Path</th>\n",
       "      <th># samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ART-DESIGN</td>\n",
       "      <td>data_cleaned\\ART-DESIGN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>CUTE</td>\n",
       "      <td>data_cleaned\\CUTE</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ADVISE-INFLUENCE</td>\n",
       "      <td>data_cleaned\\ADVISE-INFLUENCE</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>PAST</td>\n",
       "      <td>data_cleaned\\PAST</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>GUITAR</td>\n",
       "      <td>data_cleaned\\GUITAR</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>GOVERNMENT</td>\n",
       "      <td>data_cleaned\\GOVERNMENT</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AFRAID</td>\n",
       "      <td>data_cleaned\\AFRAID</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>BIG</td>\n",
       "      <td>data_cleaned\\BIG</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ANSWER</td>\n",
       "      <td>data_cleaned\\ANSWER</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AGAIN</td>\n",
       "      <td>data_cleaned\\AGAIN</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Word                      Full Path  # samples\n",
       "46         ART-DESIGN        data_cleaned\\ART-DESIGN         32\n",
       "185              CUTE              data_cleaned\\CUTE         30\n",
       "15   ADVISE-INFLUENCE  data_cleaned\\ADVISE-INFLUENCE         24\n",
       "261              PAST              data_cleaned\\PAST         24\n",
       "207            GUITAR            data_cleaned\\GUITAR         24\n",
       "205        GOVERNMENT        data_cleaned\\GOVERNMENT         24\n",
       "16             AFRAID            data_cleaned\\AFRAID         24\n",
       "95                BIG               data_cleaned\\BIG         24\n",
       "37             ANSWER            data_cleaned\\ANSWER         22\n",
       "18              AGAIN             data_cleaned\\AGAIN         22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "from IPython.core.display import display\n",
    "\n",
    "# first lets look at the data\n",
    "dataFolder = 'data_cleaned'\n",
    "wordLists = os.listdir(dataFolder)\n",
    "\n",
    "#populate the data frame with words\n",
    "ASL_df = pd.DataFrame(wordLists,columns = ['Word']);\n",
    "#populate with full paths\n",
    "ASL_df['Full Path'] = ASL_df['Word'].apply(lambda x: os.path.join(dataFolder,x))\n",
    "#populate with # samples\n",
    "ASL_df['# samples'] = ASL_df['Full Path'].apply(lambda x: len(os.listdir(x)))\n",
    "\n",
    "#sort them by largest or smallest\n",
    "ASL_df = ASL_df.sort_values(by=['# samples'],ascending = False)\n",
    "\n",
    "print('Words with the most # of examples')\n",
    "display(ASL_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class : ART-DESIGN Images have been created\n",
      "Class : CUTE Images have been created\n",
      "Class : ADVISE-INFLUENCE Images have been created\n",
      "Class : PAST Images have been created\n",
      "Class : GUITAR Images have been created\n",
      "Class : GOVERNMENT Images have been created\n",
      "Class : AFRAID Images have been created\n",
      "Class : BIG Images have been created\n",
      "Class : ANSWER Images have been created\n",
      "Class : AGAIN Images have been created\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def ImagesFromVideoFile(videoName,desDirectory,wordsampleIndex_int):\n",
    "    #get video source object\n",
    "    cap = cv2.VideoCapture(videoName)\n",
    "    w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    numFrames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    size = (h,w)    \n",
    "    count = 0\n",
    "    if(cap.isOpened()):\n",
    "        while(True):\n",
    "            #read the captured video\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if(not ret):\n",
    "                #no more frames so lets exit the loop\n",
    "                break\n",
    "            im = cv2.resize(frame, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "            #now lets just cast it and fix the channels\n",
    "#             im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "            filename = os.path.join(desDirectory,'pic_{0}_{1}.png'.format(wordsampleIndex_int,count))\n",
    "\n",
    "            retval = cv2.imwrite(filename, im)\n",
    "            count += 1\n",
    "    else:\n",
    "        print('Something wrong with VideoCapture')\n",
    "    #release the object\n",
    "    cap.release()\n",
    "\n",
    "# now for each one of these words lets process them and create folders with pictures\n",
    "import time \n",
    "NumClasses = 10\n",
    "baseDirectory = 'data_Images'\n",
    "#lets create the destination directory\n",
    "if not os.path.exists(baseDirectory):\n",
    "    os.makedirs(baseDirectory)\n",
    "    \n",
    "for index, row in ASL_df.head(NumClasses).iterrows():\n",
    "    #get the full paths of the videos\n",
    "    videoNameSources = [os.path.join(row['Full Path'],x) for x in os.listdir(row['Full Path'])]\n",
    "    destDirectory = os.path.join(baseDirectory,row['Word'])\n",
    "    if not os.path.exists(destDirectory):\n",
    "        os.makedirs(destDirectory)\n",
    "    for i, videoName in enumerate(videoNameSources):\n",
    "        ImagesFromVideoFile(videoName,destDirectory,i)\n",
    "    print('Class : {} Images have been created'.format(row['Word']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Splitting class ADVISE-INFLUENCE\n",
      "Finished Splitting class AFRAID\n",
      "Finished Splitting class AGAIN\n",
      "Finished Splitting class ANSWER\n",
      "Finished Splitting class ART-DESIGN\n",
      "Finished Splitting class BIG\n",
      "Finished Splitting class CUTE\n",
      "Finished Splitting class GOVERNMENT\n",
      "Finished Splitting class GUITAR\n",
      "Finished Splitting class PAST\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# first we have to split the data into train and validation\n",
    "import os\n",
    "import random\n",
    "baseDirectory = 'data_Images'\n",
    "ValDirectory = 'data_Images_val'\n",
    "\n",
    "if not os.path.exists(ValDirectory):\n",
    "    os.makedirs(ValDirectory)\n",
    "\n",
    "def train_test_foldSplit(baseDirectory,ValDirectory,testSize = .2):\n",
    "    trainSize = 1-testSize\n",
    "    for className in os.listdir(baseDirectory):\n",
    "        valClassFolder = os.path.join(ValDirectory,className)\n",
    "        baseClassFolder = os.path.join(baseDirectory,className)\n",
    "        \n",
    "        if not os.path.exists(valClassFolder):\n",
    "            os.makedirs(valClassFolder)\n",
    "        \n",
    "        picNames = os.listdir(baseClassFolder)\n",
    "        numSampled = int(len(picNames)*testSize)\n",
    "        picNames_sampled = random.sample(picNames,numSampled)\n",
    "        filePaths_lst = [os.path.join(baseClassFolder,x) for x in picNames_sampled ]\n",
    "        filePaths_val_lst = [os.path.join(valClassFolder,x) for x in picNames_sampled]\n",
    "        \n",
    "        for filebase,fileval in zip(filePaths_lst,filePaths_val_lst):\n",
    "            os.rename(filebase,fileval)\n",
    "        \n",
    "        print('Finished Splitting class {}'.format(className))\n",
    "    print('Done')\n",
    "        \n",
    "train_test_foldSplit(baseDirectory,ValDirectory,testSize = .2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
